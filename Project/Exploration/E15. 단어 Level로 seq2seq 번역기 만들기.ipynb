{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:06.707966Z",
     "start_time": "2020-09-24T02:42:06.704999Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re    \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.039493Z",
     "start_time": "2020-09-24T02:42:06.708861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82037</th>\n",
       "      <td>Are you going to share that?</td>\n",
       "      <td>Est-ce que vous allez partager ça ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91168</th>\n",
       "      <td>I helped my father yesterday.</td>\n",
       "      <td>Hier, j’ai aidé mon père.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164093</th>\n",
       "      <td>I always have a couple of beach towels in my car.</td>\n",
       "      <td>J'ai toujours une paire de serviettes de plage...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76062</th>\n",
       "      <td>He was desperate to escape.</td>\n",
       "      <td>Il voulait désespérément s'échapper.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138489</th>\n",
       "      <td>He seemed disappointed at the results.</td>\n",
       "      <td>Il avait l'air déçu des résultats.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "82037                        Are you going to share that?   \n",
       "91168                       I helped my father yesterday.   \n",
       "164093  I always have a couple of beach towels in my car.   \n",
       "76062                         He was desperate to escape.   \n",
       "138489             He seemed disappointed at the results.   \n",
       "\n",
       "                                                      fra  \\\n",
       "82037                 Est-ce que vous allez partager ça ?   \n",
       "91168                           Hier, j’ai aidé mon père.   \n",
       "164093  J'ai toujours une paire de serviettes de plage...   \n",
       "76062                Il voulait désespérément s'échapper.   \n",
       "138489                 Il avait l'air déçu des résultats.   \n",
       "\n",
       "                                                       cc  \n",
       "82037   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "91168   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "164093  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "76062   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "138489  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.057125Z",
     "start_time": "2020-09-24T02:42:07.040354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66315</th>\n",
       "      <td>What's your real purpose?</td>\n",
       "      <td>Quel est votre réel objectif ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60795</th>\n",
       "      <td>Don't use too much water.</td>\n",
       "      <td>N'utilisez pas trop d'eau.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67135</th>\n",
       "      <td>Your French is excellent.</td>\n",
       "      <td>Votre français est excellent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92347</th>\n",
       "      <td>I'm still intimidated by you.</td>\n",
       "      <td>Tu m'intimides toujours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91436</th>\n",
       "      <td>I only know what you tell me.</td>\n",
       "      <td>Je ne sais que ce que vous me dites.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 eng                                   fra\n",
       "66315      What's your real purpose?        Quel est votre réel objectif ?\n",
       "60795      Don't use too much water.            N'utilisez pas trop d'eau.\n",
       "67135      Your French is excellent.         Votre français est excellent.\n",
       "92347  I'm still intimidated by you.              Tu m'intimides toujours.\n",
       "91436  I only know what you tell me.  Je ne sais que ce que vous me dites."
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.065580Z",
     "start_time": "2020-09-24T02:42:07.058132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"You've got to help them.\", \"You've got to help them.\",\n",
       "       \"You've got to stop this.\", ..., \"Obviously, there's a problem.\",\n",
       "       'Oil is extracted from olives.', 'Old habits are hard to break.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정제, 정규화, 전처리 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 소문자 변경 후 구두점 분리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.078380Z",
     "start_time": "2020-09-24T02:42:07.066612Z"
    }
   },
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    # 소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    # 구두점(Punctuation)을 단어와 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄어쓰기 단위로 토큰화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.088838Z",
     "start_time": "2020-09-24T02:42:07.079546Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  \n",
    "        filters=' ',   \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어, 프랑스어 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.664834Z",
     "start_time": "2020-09-24T02:42:07.089865Z"
    }
   },
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:07.672511Z",
     "start_time": "2020-09-24T02:42:07.665883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.316454Z",
     "start_time": "2020-09-24T02:42:07.673413Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 8, 313, 36, 135, 4, 3],\n",
       " [2, 15, 115, 36, 135, 4, 3],\n",
       " [2, 15, 115, 159, 229, 12, 4, 3],\n",
       " [2, 8, 313, 159, 229, 12, 4, 3],\n",
       " [2, 15, 115, 1760, 50, 3],\n",
       " [2, 8, 313, 1760, 50, 3],\n",
       " [2, 15, 19, 52, 83, 27, 206, 4, 3],\n",
       " [2, 8, 19, 55, 83, 27, 206, 4, 3],\n",
       " [2, 8, 55, 47, 223, 4, 3],\n",
       " [2, 15, 52, 47, 223, 4, 3]]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input, target 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.408003Z",
     "start_time": "2020-09-24T02:42:08.320511Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.411266Z",
     "start_time": "2020-09-24T02:42:08.409121Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.724842Z",
     "start_time": "2020-09-24T02:42:08.412137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 11)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.728291Z",
     "start_time": "2020-09-24T02:42:08.725786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.750134Z",
     "start_time": "2020-09-24T02:42:08.729282Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5932\n",
      "프랑스어 단어장의 크기 : 8507\n",
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.777325Z",
     "start_time": "2020-09-24T02:42:08.751082Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:42:08.784171Z",
     "start_time": "2020-09-24T02:42:08.778467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 11)\n",
      "(30000, 20)\n",
      "(30000, 20)\n",
      "(3000, 11)\n",
      "(3000, 20)\n",
      "(3000, 20)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:49:26.091256Z",
     "start_time": "2020-09-24T02:49:25.476357Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:49:26.784028Z",
     "start_time": "2020-09-24T02:49:26.193095Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:49:26.914694Z",
     "start_time": "2020-09-24T02:49:26.898013Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:49:27.032908Z",
     "start_time": "2020-09-24T02:49:27.023537Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T02:49:27.773281Z",
     "start_time": "2020-09-24T02:49:27.768596Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, None, 512)    3037184     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, None, 512)    4355584     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking_18 (Masking)            (None, None, 512)    0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "masking_19 (Masking)            (None, None, 512)    0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  [(None, 512), (None, 2099200     masking_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, None, 512),  2099200     masking_19[0][0]                 \n",
      "                                                                 lstm_18[0][1]                    \n",
      "                                                                 lstm_18[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 8507)   4364091     lstm_19[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,955,259\n",
      "Trainable params: 15,955,259\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:12:07.759334Z",
     "start_time": "2020-09-24T02:49:31.333993Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 1.7852 - val_loss: 1.4841\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 1.3542 - val_loss: 1.2671\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 1.1743 - val_loss: 1.1416\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 1.0494 - val_loss: 1.0591\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.9530 - val_loss: 1.0035\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.8782 - val_loss: 0.9574\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.8172 - val_loss: 0.9326\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.7679 - val_loss: 0.9173\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.7279 - val_loss: 0.9048\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.6990 - val_loss: 0.9046\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 27s 28ms/step - loss: 0.6776 - val_loss: 0.9033\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.6603 - val_loss: 0.9060\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.6472 - val_loss: 0.9031\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.6215 - val_loss: 0.8895\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.6051 - val_loss: 0.8949\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5967 - val_loss: 0.8965\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5862 - val_loss: 0.8994\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5754 - val_loss: 0.8953\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5658 - val_loss: 0.8906\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5499 - val_loss: 0.8881\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.5369 - val_loss: 0.8881\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.5317 - val_loss: 0.8890\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5254 - val_loss: 0.8898\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5208 - val_loss: 0.8868\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.5177 - val_loss: 0.8903\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.5138 - val_loss: 0.8862\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 25s 26ms/step - loss: 0.5090 - val_loss: 0.8889\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.5036 - val_loss: 0.8885\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.4998 - val_loss: 0.8865\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 24s 26ms/step - loss: 0.4930 - val_loss: 0.8819\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.4880 - val_loss: 0.8800\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.4824 - val_loss: 0.8809\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 26s 27ms/step - loss: 0.4779 - val_loss: 0.8764\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.4741 - val_loss: 0.8767\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.4700 - val_loss: 0.8769\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4679 - val_loss: 0.8744\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.4650 - val_loss: 0.8725\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4615 - val_loss: 0.8770\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 26s 28ms/step - loss: 0.4601 - val_loss: 0.8730\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.4576 - val_loss: 0.8755\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 27s 29ms/step - loss: 0.4560 - val_loss: 0.8744\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4550 - val_loss: 0.8753\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4522 - val_loss: 0.8707\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.4508 - val_loss: 0.8718\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.4489 - val_loss: 0.8735\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 31s 33ms/step - loss: 0.4469 - val_loss: 0.8721\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4449 - val_loss: 0.8750\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4436 - val_loss: 0.8736\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 28s 30ms/step - loss: 0.4412 - val_loss: 0.8753\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 28s 29ms/step - loss: 0.4397 - val_loss: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f790b6ffa10>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:12:15.046533Z",
     "start_time": "2020-09-24T03:12:15.041653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_21 (Embedding)     (None, None, 512)         3037184   \n",
      "_________________________________________________________________\n",
      "masking_18 (Masking)         (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 5,136,384\n",
      "Trainable params: 5,136,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:33.679780Z",
     "start_time": "2020-09-24T03:14:33.525419Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:34.154054Z",
     "start_time": "2020-09-24T03:14:34.152297Z"
    }
   },
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:34.938203Z",
     "start_time": "2020-09-24T03:14:34.931647Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, None, 512)    4355584     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, None, 512),  2099200     embedding_26[0][0]               \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 8507)   4364091     lstm_19[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,818,875\n",
      "Trainable params: 10,818,875\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:35.496509Z",
     "start_time": "2020-09-24T03:14:35.492924Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:36.008471Z",
     "start_time": "2020-09-24T03:14:36.006508Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:36.350914Z",
     "start_time": "2020-09-24T03:14:36.348567Z"
    }
   },
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T03:14:38.844455Z",
     "start_time": "2020-09-24T03:14:37.314057Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: i want to ask you something . \n",
      "정답 문장: je veux vous demander quelque chose . \n",
      "번역기가 번역한 문장:  je veux te vous quelqu\n",
      "-----------------------------------\n",
      "입력 문장: stop playing hard to get . \n",
      "정답 문장: cessez de faire ceux qui ne sont pas int ress s ! \n",
      "번역기가 번역한 문장:  arr de de faire fair\n",
      "-----------------------------------\n",
      "입력 문장: you never have any money . \n",
      "정답 문장: tu ne disposes jamais d aucun argent . \n",
      "번역기가 번역한 문장:  tu n jamais d d d d \n",
      "-----------------------------------\n",
      "입력 문장: tom slipped and nearly fell . \n",
      "정답 문장: tom <unk> et <unk> tomber . \n",
      "번역기가 번역한 문장:  tom a les et en en \n",
      "-----------------------------------\n",
      "입력 문장: tom kept the window closed . \n",
      "정답 문장: tom garda la fen tre ferm e . \n",
      "번역기가 번역한 문장:  tom tom la la la la l\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,201,501,1004,2015]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마무리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 문장: i want to ask you something .   \n",
    "정답 문장: je veux vous demander quelque chose .   \n",
    "번역기가 번역한 문장:  je veux te vous quelqu  \n",
    "\n",
    "입력 문장: stop playing hard to get .   \n",
    "정답 문장: cessez de faire ceux qui ne sont pas int ress s !  <br>\n",
    "번역기가 번역한 문장:  arr de de faire fair  \n",
    "\n",
    "입력 문장: you never have any money .   \n",
    "정답 문장: tu ne disposes jamais d aucun argent .   \n",
    "번역기가 번역한 문장:  tu n jamais d d d d   \n",
    "\n",
    "입력 문장: tom slipped and nearly fell .   \n",
    "정답 문장: tom <unk> et <unk> tomber .   \n",
    "번역기가 번역한 문장:  tom a les et en en   \n",
    "\n",
    "입력 문장: tom kept the window closed .   \n",
    "정답 문장: tom garda la fen tre ferm e .   \n",
    "번역기가 번역한 문장:  tom tom la la la la l  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "번역기가 번역한 문장이 완벽하지는 않지만, 어느정도 비슷한 결과를 보이고 있습니다.  \n",
    "학습 데이터가 더 많거나, 전처리 부분에 신경을 많이 쓴다면 더 좋은 결과를 얻을 것이라고 생각 됩니다.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
