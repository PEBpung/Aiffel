{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  moviepy로 비디오 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoClip, VideoFileClip\n",
    "from moviepy.editor import ipython_display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비디오 읽고 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/404 [00:00<?, ?it/s, now=None]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "MoviePy - Writing audio in mvpyresultTEMP_MPY_wvf_snd.mp3\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n"
     ]
    }
   ],
   "source": [
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "#ipython_display() 는 동영상을 주피터 노트북에 렌더링할 수 있게 도와주는 함수.\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "result_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "clip.write_videofile(result_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**moviepy** 를 이용해서 주피터 노트북 상에서 비디오를 읽고 쓰는 프로그램을 작성했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어둡게 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  14%|█▍        | 57/403 [00:00<00:00, 569.26it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4\n"
     ]
    }
   ],
   "source": [
    "# 위와 같이 동영상을 다시 읽어줍니다. \n",
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "# clip에서 numpy로 데이터를 추출합니다. \n",
    "vlen=int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    # 어둡게 만들기\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "    \n",
    "# 새 clip 만들기 \n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "# 쓰기\n",
    "result_video_path2 = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult2.mp4'\n",
    "outclip.write_videofile(result_video_path2, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**moviepy** 로 읽은 동영상을 numpy 형태로 변환하고 영상 밝기를 50% 어둡게 만듭니다. frame 별로 이 과정이 진행됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읽고 쓰는 시간을 측정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 1 : moviepy 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  14%|█▍        | 58/403 [00:00<00:00, 568.38it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "[INFO] moviepy time : 2.54ms\n"
     ]
    }
   ],
   "source": [
    "start = cv2.getTickCount()\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "\n",
    "vlen = int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "\n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "mvpy_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "outclip.write_videofile(mvpy_video_path, fps=30)\n",
    "\n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] moviepy time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 2 : OpenCV 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cv time : 1.24ms\n"
     ]
    }
   ],
   "source": [
    "start = cv2.getTickCount()\n",
    "vc = cv2.VideoCapture(video_path)\n",
    "\n",
    "cv_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/cvresult.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "vw = cv2.VideoWriter(cv_video_path, fourcc, 30, (640,360))\n",
    "\n",
    "vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "for i in range(vlen):\n",
    "    ret, img = vc.read()\n",
    "    if ret == False: break\n",
    "    \n",
    "    img_result = cv2.resize(img, (640, 360)) * 0.5\n",
    "    vw.write(img_result.astype(np.uint8))\n",
    "    \n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] cv time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moviepy 를 이용할 때의 장단점을 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moviepy을 이용하면 numpy를 사용할 수 있는 장점이 있습니다. 그래서 다양한 효과를 추가 할수 있습니다.  \n",
    "하지만 openCV와 비교했을 때 moviepy은 2.54ms의 시간이 걸리고 CV는 1.24ms가 걸립니다.  \n",
    "무려 두배나 차이나기 때문에 실시간 비디오나 대용량 비디오 처리에는 적합하지 않아 보입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어디까지 만들고 싶은지 정의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 스티커앱 인식 거리 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카페에서 실험한 결과 조명과 배경이 적절해서 그런지 인식이 잘 됐습니다.  \n",
    "카메라에 얼굴이 잘릴 정도로 가까이 가면 인식이 잘 되지 않았습니다.  \n",
    "팔보다 더 먼 거리에서 측정한 결과는 성능이 좋았습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. yaw, pitch, roll 각도 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의로 각도를 재는데 어려움이 있었습니다.  \n",
    "그래서 사용자가 주로 촬영하는 각도에서 스티커가 잘 동작하는지를 지표로 삼았습니다.  \n",
    "그 결과 yaw (고개를 좌우로 틀었을 때) 시야에서 카메라가 있을 때는 동작이 잘 됩니다.  \n",
    "roll(고개를 갸우뚱 했을때) 45도 정도 밖으로 가면 인식이 잘 안됐습니다.  \n",
    "pitch (고개를 끄덕였을 때) 앞선 각도보다 민감하게 작용했습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. 스티커앱의 스펙 정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "허용 거리: 셀카를 찍을 때 정도의 거리로 25cm ~ 1m  \n",
    "인원 수: 4명 -> 한팔로 카메라를 들었을 때 카메라에 들어올 수 있는 인원수\n",
    "허용 각도: pitch : -20 ~ 30도, yaw : -45 ~ 45도, roll : -45 ~ 45도- > 화면을 바라볼 수 있는 각도  \n",
    "마스크 유무: 마스크를 써도 인식할 수 있는 스티커앱 만들기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스티커 Out Bound 예외처리 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 스티커앱의 예외 상황"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스티커가 없는 경우 얼굴이 경계에서 벗어나도 예외 상황은 발생하지 않습니다.  \n",
    "하지만 스티커가 좌우 경계 밖으로 나가는 경우 예외 상황이 발생하며 앱이 멈추게 됩니다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 문제가 발생 코드 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "newaddsticker.py의 img2sticker 메소드에서 왼쪽 경계를 벗어나서 detection 되는 경우 refined_x 의 값이 음수가 됩니다.  \n",
    "그래서 예외 처리로 refined_x < 0일 때 스티커를 잘라주는 코드를 작성해줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 칼만 필터 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1번 그림: 웹캠 결과, 2번 그림: 동영상 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"data/img/kf.png\" width =\"200\" />   <img src = \"data/img/kf1.png\" width =\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "칼만 필터를 적용한 경우 얼굴을 detect 하지 못하는 문제가 발생했습니다.  \n",
    "칼만 필터가 이전 측정값 전체의 평균을 사용하기 때문에 문제가 발생하는 줄 알고 수정을 하려고 했습니다.  \n",
    "하지만 해당 코드에서는 이동 평균 필터를 사용하고 있었습니다.  \n",
    "동영상으로 다시 테스트 한 결과 성능이 나아진 모습을 보였지만, 웹캠에 적용하는 데 문제가 있습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
